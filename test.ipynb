{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26377"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('有')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AH0', 'S', 'IH1', 'CH', 'AH0', 'M', 'sp3', 'f', 'en1', 'sp2', 'AE1', 'S', 'K', 'IY0', 'M', 'AE1', 'TH']\n",
      "['0', '0', '0', '0', '0', '#3', '0', '0', '#2', '0', '0', '0', '0', '#1', '0', '0', '#4']\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import json\n",
    "import requests\n",
    "import itertools\n",
    "\n",
    "url = 'http://hmi.chengjiukehu.com/g2p-pp-service'\n",
    "headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "data = {\n",
    "    'user_id': '',\n",
    "    'request_id': '974d59c5-34b8-4635-a797-0fe4f3c030a0',\n",
    "    'session_id': '',\n",
    "    'trace_id': '',\n",
    "    'span_id': '',\n",
    "    'text': 'asciimath 分 ascii math'\n",
    "}\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "if response.status_code == 200:\n",
    "    res = json.loads(response.text)\n",
    "    phonemes, prosodies = res['phonemes'], res['prosodies']\n",
    "    phonemes = list(itertools.chain(*phonemes))\n",
    "    prosodies = list(itertools.chain(*prosodies))\n",
    "    indices = sorted([index for index, value in enumerate(phonemes) if value == 'xer'], reverse=True)\n",
    "    #for index in indices:\n",
    "    #    phonemes[index] = 'er2'\n",
    "print(phonemes)\n",
    "print(prosodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import soundfile as sf\n",
    "\n",
    "def convert_audio(audio_data, sample_rate=24000, bit_depth=16, channels=1, format='mp3'):\n",
    "    # 将NDArray转换为指定位深格式\n",
    "    if bit_depth == 16:\n",
    "        audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n",
    "    elif bit_depth == 24:\n",
    "        audio_data = np.asarray(audio_data * 8388607, dtype=np.int32)\n",
    "    elif bit_depth == 32:\n",
    "        audio_data = np.asarray(audio_data * 2147483647, dtype=np.int32)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported bit depth. Please use 16, 24, or 32.\")\n",
    "    \n",
    "    if format == 'wav':\n",
    "        audio_segment = AudioSegment(\n",
    "            audio_data.tobytes(), \n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=audio_data.dtype.itemsize, \n",
    "            channels=channels\n",
    "        )\n",
    "        wav_data = audio_segment.export(format=format, bitrate='64k')\n",
    "        return wav_data.read()\n",
    "    elif format == 'pcm':\n",
    "        return audio_data.tobytes()\n",
    "    elif format == 'mp3':\n",
    "        audio_segment = AudioSegment(\n",
    "            audio_data.tobytes(), \n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=audio_data.dtype.itemsize, \n",
    "            channels=channels\n",
    "        )\n",
    "        mp3_data = audio_segment.export(format=format, bitrate='64k')\n",
    "        return mp3_data.read()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported format. Please use 'wav', 'pcm', or 'mp3'.\")\n",
    "    \n",
    "def convert_audio_tobyte(data, format='mp3'):\n",
    "        if format == 'wav':\n",
    "            audio_buffer = io.BytesIO()\n",
    "            audio_buffer.write(data)\n",
    "            return audio_buffer.getvalue()\n",
    "\n",
    "        elif format == 'pcm':\n",
    "            # with open(filename, 'wb') as pcm_file:\n",
    "            #     pcm_file.write(data)\n",
    "            audio_buffer = io.BytesIO()\n",
    "            audio_buffer.write(data)\n",
    "            return audio_buffer.getvalue()\n",
    "        elif format == 'mp3':\n",
    "            # with open(filename, 'wb') as mp3_file:\n",
    "            #     mp3_file.write(data)\n",
    "            audio_buffer = io.BytesIO()\n",
    "            audio_buffer.write(data)\n",
    "            return audio_buffer.getvalue()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Unsupported format. Please use 'wav', 'pcm', or 'mp3'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "embedded null byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m time1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      7\u001b[0m wav_data \u001b[38;5;241m=\u001b[39m convert_audio(audio_data, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--silent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput.mp3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m time2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcm 转 wav 耗时：\u001b[39m\u001b[38;5;124m'\u001b[39m, (time2 \u001b[38;5;241m-\u001b[39m time1)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/cfs/SPEECH/hupeng/tools/env/miniconda3/envs/py310/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    500\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/mnt/cfs/SPEECH/hupeng/tools/env/miniconda3/envs/py310/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/mnt/cfs/SPEECH/hupeng/tools/env/miniconda3/envs/py310/lib/python3.10/subprocess.py:1796\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1794\u001b[0m     fds_to_keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(pass_fds)\n\u001b[1;32m   1795\u001b[0m     fds_to_keep\u001b[38;5;241m.\u001b[39madd(errpipe_write)\n\u001b[0;32m-> 1796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid \u001b[38;5;241m=\u001b[39m \u001b[43m_posixsubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfork_exec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m            \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfds_to_keep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrpipe_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrpipe_write\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_child_created \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;66;03m# be sure the FD is closed no matter what\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: embedded null byte"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "pcm_file_path = '/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend/vits/poem/tts_audios/96_neutral_14_10_18.pcm'\n",
    "audio_data = np.fromfile(pcm_file_path, dtype=np.int16)\n",
    "\n",
    "audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n",
    "audio_segment = AudioSegment(\n",
    "    audio_data.tobytes(), \n",
    "    frame_rate=24000,\n",
    "    sample_width=audio_data.dtype.itemsize, \n",
    "    channels=1\n",
    ")\n",
    "wav_data = audio_segment.export(format='wav', bitrate='64k')\n",
    "wav_data = wav_data.read()\n",
    "    \n",
    "time1 = time.time()\n",
    "subprocess.run(['lame', '--silent', wav_data, 'output.mp3'])\n",
    "time2 = time.time()\n",
    "print('pcm 转 wav 耗时：', (time2 - time1)*1000,'ms')\n",
    "\n",
    "res = convert_audio_tobyte(wav_data, format='mp3')\n",
    "time3 = time.time()\n",
    "print('mp3 转 byte耗时：',(time3 - time2)*1000,'ms')\n",
    "\n",
    "with open('test_data/audio/time_test.mp3', 'wb') as f:\n",
    "    f.write(wav_data)\n",
    "time4 = time.time()\n",
    "print('mp3 存储到本地耗时：',(time4 - time3)*1000,'ms') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpge 转 pcm 为 mp3 并存储到本地耗时 73.58098030090332 ms\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "pcm_file_path = '/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend/vits/poem/tts_audios/96_neutral_14_10_18.pcm'\n",
    "audio_data = np.fromfile(pcm_file_path, dtype=np.int16)\n",
    "\n",
    "time1 = time.time()\n",
    "subprocess.run(['ffmpeg', '-y', '-f', 's16le', '-ar', '44100', '-ac', '1', '-i', pcm_file_path, 'test_data/audio/time_test.mp3'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "time2 = time.time()\n",
    "print('ffmpge 转 pcm 为 mp3 并存储到本地耗时',(time2 - time1)*1000,'ms')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg 转 pcm 为 mp3 并获取字节流耗时 64.06450271606445 ms\n"
     ]
    }
   ],
   "source": [
    "pcm_file_path = '/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend/vits/poem/tts_audios/96_neutral_14_10_18.pcm'\n",
    "audio_data = np.fromfile(pcm_file_path, dtype=np.int16)\n",
    "\n",
    "pcm_byte_stream = audio_data.tobytes()\n",
    "\n",
    "time1 = time.time()\n",
    "result = subprocess.run(['ffmpeg', '-y', '-f', 's16le', '-ar', '24000', '-ac', '1', '-i', 'pipe:0', '-f', 'mp3', 'pipe:1'],\n",
    "                        input=pcm_byte_stream, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)\n",
    "mp3_byte_stream = result.stdout\n",
    "time2 = time.time()\n",
    "print('ffmpeg 转 pcm 为 mp3 并获取字节流耗时', (time2 - time1) * 1000, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1452928/1437504894.py:11: RuntimeWarning: overflow encountered in multiply\n",
      "  audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n",
      "/tmp/ipykernel_1452928/1437504894.py:11: RuntimeWarning: invalid value encountered in multiply\n",
      "  audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n",
      "/tmp/ipykernel_1452928/1437504894.py:11: RuntimeWarning: invalid value encountered in cast\n",
      "  audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均耗时： 26.34507417678833 ms\n",
      "平均耗时： 0.048623085021972656 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "import io\n",
    "\n",
    "# 假设你的 PCM 文件路径\n",
    "pcm_file_path = '/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend/vits/poem/tts_audios/96_neutral_14_10_18.pcm'\n",
    "audio_data = np.fromfile(pcm_file_path, dtype=np.float32)\n",
    "\n",
    "audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n",
    "\n",
    "total_time, total_time_2 = 0, 0\n",
    "for _ in range(100):\n",
    "    \n",
    "    pcm2wav_time1 = time.time()\n",
    "    audio_segment = AudioSegment(\n",
    "    audio_data.tobytes(), \n",
    "    frame_rate=24000,\n",
    "    sample_width=audio_data.dtype.itemsize, \n",
    "    channels=1\n",
    "    )\n",
    "    \n",
    "    wav_io = io.BytesIO()\n",
    "    audio_segment.export(wav_io, format='wav', bitrate='64k')\n",
    "    wav_io.seek(0)\n",
    "    pcm2wav_time2 = time.time()\n",
    "    total_time_2 += (pcm2wav_time2 - pcm2wav_time1) * 1000 \n",
    "\n",
    "    # 使用 subprocess 调用 lame，将 WAV 数据通过管道传递并获取 MP3 字节流\n",
    "    time1 = time.time()\n",
    "    process = subprocess.Popen(\n",
    "        ['lame', '--silent', '-', '-'],\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE\n",
    "    )\n",
    "\n",
    "    # 将 WAV 字节流写入 stdin 并从 stdout 读取 MP3 字节流\n",
    "    mp3_byte_stream, _ = process.communicate(input=wav_io.read())\n",
    "    time2 = time.time()\n",
    "    total_time += (time2 - time1) * 1000 \n",
    "\n",
    "average_time = total_time / 100\n",
    "print('平均耗时：', average_time, 'ms')\n",
    "\n",
    "average_time = total_time_2 / 100\n",
    "print('平均耗时：', average_time, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1452928/3777487097.py:11: RuntimeWarning: overflow encountered in multiply\n",
      "  audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n",
      "/tmp/ipykernel_1452928/3777487097.py:11: RuntimeWarning: invalid value encountered in multiply\n",
      "  audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n",
      "/tmp/ipykernel_1452928/3777487097.py:11: RuntimeWarning: invalid value encountered in cast\n",
      "  audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均耗时： 54.166104793548584 ms\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "import io\n",
    "\n",
    "# 假设你的 PCM 文件路径\n",
    "pcm_file_path = '/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend/vits/poem/tts_audios/96_neutral_14_10_18.pcm'\n",
    "audio_data = np.fromfile(pcm_file_path, dtype=np.float32)\n",
    "\n",
    "audio_data = np.asarray(audio_data * 32767, dtype=np.int16)\n",
    "\n",
    "total_time, total_time_2 = 0, 0\n",
    "for _ in range(100):\n",
    "    \n",
    "    pcm2wav_time1 = time.time()\n",
    "    \n",
    "    audio_segment = AudioSegment(\n",
    "    audio_data.tobytes(), \n",
    "    frame_rate=24000,\n",
    "    sample_width=audio_data.dtype.itemsize, \n",
    "    channels=1\n",
    "    )\n",
    "    \n",
    "    wav_io = io.BytesIO()\n",
    "    audio_segment.export(wav_io, format='mp3', bitrate='64k')\n",
    "    wav_io.seek(0)\n",
    "    pcm2wav_time2 = time.time()\n",
    "    total_time_2 += (pcm2wav_time2 - pcm2wav_time1) * 1000 \n",
    "\n",
    "average_time = total_time_2 / 100\n",
    "print('平均耗时：', average_time, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg 转 pcm 为 wav 平均耗时 44.66773509979248 ms\n"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "pcm_file_path = '/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend/vits/poem/tts_audios/96_neutral_14_10_18.pcm'\n",
    "audio_data = np.fromfile(pcm_file_path, dtype=np.int16)\n",
    "\n",
    "pcm_byte_stream = audio_data.tobytes()\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "# 循环100次，计算平均耗时\n",
    "for _ in range(100):\n",
    "    # 使用 ffmpeg 将 PCM 数据转换为 MP3 字节流\n",
    "    process = (\n",
    "        ffmpeg\n",
    "        .input('pipe:0', format='s16le', ar=24000, ac=1)\n",
    "        .output('pipe:1', format='wav')\n",
    "        .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True)\n",
    "    )\n",
    "\n",
    "    time1 = time.time()\n",
    "    \n",
    "    # 向 ffmpeg 进程写入 PCM 数据并获取输出\n",
    "    out, err = process.communicate(input=pcm_byte_stream)\n",
    "    \n",
    "    time2 = time.time()\n",
    "\n",
    "    total_time += (time2 - time1) * 1000  # 以毫秒为单位\n",
    "\n",
    "average_time = total_time / 100\n",
    "print('ffmpeg 转 pcm 为 wav 平均耗时', average_time, 'ms')\n",
    "\n",
    "# 获取 MP3 字节流\n",
    "mp3_byte_stream = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg 转 pcm 为 mp3 并获取字节流平均耗时 61.42758131027222 ms\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 读取 PCM 文件\n",
    "pcm_file_path = '/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend/vits/poem/tts_audios/96_neutral_14_10_18.pcm'\n",
    "audio_data = np.fromfile(pcm_file_path, dtype=np.int16)\n",
    "\n",
    "pcm_byte_stream = audio_data.tobytes()\n",
    "\n",
    "total_time = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    time1 = time.time()\n",
    "    result = subprocess.run(\n",
    "        ['ffmpeg', '-y', '-f', 's16le', '-ar', '24000', '-ac', '1', '-i', 'pipe:0', '-f', 'mp3', 'pipe:1'],\n",
    "        input=pcm_byte_stream,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.DEVNULL\n",
    "    )\n",
    "    time2 = time.time()\n",
    "    total_time += (time2 - time1) * 1000  \n",
    "\n",
    "average_time = total_time / 100  # 计算平均耗时\n",
    "print('ffmpeg 转 pcm 为 mp3 并获取字节流平均耗时', average_time, 'ms')\n",
    "\n",
    "mp3_byte_stream = result.stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "input = '<speak voice_type=\\\"xiaosi\\\" emotion=\\\"happy\\\" volume=\\\"0.9\\\" rate=\\\"1.1\\\" pitch=\\\"1.0\\\"> 你好啊,今天天气</speak>'\n",
    "\n",
    "if re.search(r'(<speak.*?>)(.*?)(</speak>)', input, re.DOTALL):\n",
    "    print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(<speak.*?>)(.*?)(</speak>)', input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UUID('84913546-88a0-45b4-aad3-bc65efc7cc9c')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tal_frontend.frontend.normalizer.cn.cn_normalizer import cn_Normalizer as cn_Normalizer\n",
    "from tal_frontend.frontend.normalizer.en.en_normalizer import en_normalize\n",
    "\n",
    "zh_normalizer = cn_Normalizer()\n",
    "en_normalizer = en_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"it's a good day good-looking boy it''s good--looking\"\n",
    "for _ in range(100):\n",
    "    en_normalizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'题目给出了一次函数y等于k x加b，给定了两个点（一,一）和（二, 四），这两个点都在函数上，  一 一加一等于二'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_normalizer.normalize('题目给出了一次函数y等于k x加b，给定了两个点（1,1）和（2,-4），这两个点都在函数上， -1 1+1=2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "减\n",
      "加\n",
      "加\n",
      "除以\n",
      "减\n",
      "等于\n",
      "加\n",
      "除以\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text = \"!@#$%^&*()_-++[{]}\\|;:''\"\",.<>?/！@#¥%……&*（）-——=+「【『「」』】、｜；：‘’“”，。《》？/]\"\n",
    "no_read = ''\n",
    "for i in text:\n",
    "    res = zh_normalizer.normalize(i)\n",
    "    if not re.match(r'[\\u4e00-\\u9fff]', res):\n",
    "        no_read += i\n",
    "    else:\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"!@#$%^&*()_[{]}\\\\|;:'',.<>?！@#¥%……&*（）——「【『「」』】、｜；：‘’“”，。《》？]\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from clients.utils import math_request\n",
    "\n",
    "formular2text_url = 'http://123.57.25.89:8023/inference'\n",
    "\n",
    "def remove_spaces_between_cn_en(text):\n",
    "    punctuations = r'\\.\\,\\?\\:\\!\\，\\。\\；\\：\\、\\！\\？\\\"'\n",
    "    text = re.sub(r'[ ]+', ' ', text)\n",
    "    \n",
    "    # 移除标点符号前后的空格\n",
    "    text = re.sub(r'\\s+([{}])'.format(re.escape(punctuations)), r'\\1', text)\n",
    "    #text = re.sub(r'([{}])\\s+'.format(re.escape(punctuations)), r'\\1', text)\n",
    "    \n",
    "    # 移除中文和英文字符之间的空格\n",
    "    text = re.sub(r'([\\u4e00-\\u9fff]) (\\w)', r'\\1\\2', text)\n",
    "    text = re.sub(r'(\\w) ([\\u4e00-\\u9fff])', r'\\1\\2', text)\n",
    "    text = re.sub(r'[ ]?#9[ ]?', '#9', text)\n",
    "    return text.strip(' ')\n",
    "\n",
    "#fo = open(r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/qqx_latex_norm', 'w', encoding='utf8')\n",
    "\n",
    "text_file = r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/qqx_latex'\n",
    "with open(text_file, 'r', encoding='utf8') as fin:\n",
    "    for line in fin:\n",
    "        try:\n",
    "            text = line.strip()\n",
    "            text = '$\\Delta$'\n",
    "            text = text.replace('\\\\\\\\','\\\\')\n",
    "            detected_text = math_request(\n",
    "                    text, formular2text_url, type='latex')\n",
    "        \n",
    "            detected_text = remove_spaces_between_cn_en(detected_text)\n",
    "            #fo.write(f'{text}\\t{detected_text}\\n')\n",
    "            print(detected_text)\n",
    "            break\n",
    "        except:\n",
    "            print(text)\n",
    "#fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr( 22909)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('一行', 'm'), ('白鹭', 'nr'), ('上', 'f'), ('青天', 't')]\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg\n",
    "import re\n",
    "\n",
    "word = '一 行  白 鹭 上 青 天 '\n",
    "\n",
    "word = re.sub(r' ', '', word)\n",
    "\n",
    "word_list = jieba.posseg.cut(word)\n",
    "res = []\n",
    "for word, pos in word_list:\n",
    "    res.append((word, pos))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'上'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(19978)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/SPEECH/hupeng/tools/env/miniconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly phonemes: ['HH EH0 L OW1']\n",
      "hello\n",
      "g2p bert res: [['hello world ', ['HH EH0 L OW1', 'W ER1 L D'], 'en']]\n",
      "g2p res: ['HH EH0 L OW1', 'W ER1 L D']\n",
      "HH EH0 L OW1\n",
      "W ER1 L D\n"
     ]
    }
   ],
   "source": [
    "from tal_frontend.frontend.g2p.bertg2pw.g2p_client import TAL_G2P_Triton\n",
    "url = \"112.126.23.219:80\"\n",
    "    \n",
    "client = TAL_G2P_Triton(url)\n",
    "sentencs = [\"hello world\"]\n",
    "res, phonemes_id = client.infer(sentencs)\n",
    "print(res)\n",
    "print(phonemes_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rember : ['0', '0', '0', '0', '#1']\n",
      "to : ['0', '#1']\n",
      "be : ['0', '#1']\n",
      "happy : ['0', '0', '0', '#1']\n",
      "! : ['#3']\n",
      "['0', '0', '0', '0', '#1', '0', '#1', '0', '#1', '0', '0', '0', '#1', '#3']\n",
      "['R', 'EH1', 'M', 'B', 'ER0', 'T', 'UW1', 'B', 'IY1', 'HH', 'AE1', 'P', 'IY0', 'sp3']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "rhys =  [0, 0, 0, 0, 0]\n",
    "\n",
    "phonemes = ['R EH1 M B ER0', 'T UW1', 'B IY1', 'HH AE1 P IY0']\n",
    "\n",
    "words = ['rember', 'to', 'be', 'happy', '!']\n",
    "\n",
    "id2rhy = {1:'#0', 2:'#1', 3:'#2', 4:'#3'}\n",
    "rhy_res = ['#0']\n",
    "phonemes_res = []\n",
    "for word, rhy in zip(words, rhys):\n",
    "    if re.match(r'[\\,\\.\\?\\:\\!，。；：、！？]', word):\n",
    "        rhy_res.append('#3')\n",
    "        tmp_rhy = ['#3']\n",
    "        phonemes_res.append('sp3')\n",
    "    elif rhy != 0:\n",
    "        phoneme = phonemes.pop(0)\n",
    "        phoneme = phoneme.split()\n",
    "        tmp_rhy = ['0'] * (len(phoneme))\n",
    "        tmp_rhy[-1] = id2rhy[rhy]\n",
    "        rhy_res.extend(tmp_rhy)\n",
    "        phonemes_res.extend(phoneme)\n",
    "    else:\n",
    "        if rhy_res[-1] == '#0':\n",
    "            rhy_res[-1] = '#1'\n",
    "        phoneme = phonemes.pop(0)\n",
    "        phoneme = phoneme.split()\n",
    "        tmp_rhy = ['0'] * (len(phoneme))\n",
    "        tmp_rhy[-1] = '#1'\n",
    "        rhy_res.extend(tmp_rhy)\n",
    "        phonemes_res.extend(phoneme)\n",
    "    print(word, ':', tmp_rhy)\n",
    "rhy_res = rhy_res[1:]\n",
    "print(rhy_res)\n",
    "print(phonemes_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"你好\"\n",
    "match_en = re.match(r'^[a-zA-Z0-9]+', text)\n",
    "\n",
    "if match_en:\n",
    "    en_word = match_en.group(0)\n",
    "    print(en_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 27\n"
     ]
    }
   ],
   "source": [
    "a = ['#0', '0', '#1', '0', '#0', '0', '#1', '0', '#0', '0', '#1', '0', '#0', '0', '#0', '0', '#0', '0', '#1', '0', '#0', '0', '#1', '0', '0', '#1', '#3']\n",
    "b = ['uo3', 'm', 'en5', 'x', 'u1', 'y', 'ao1', 'q', 'iou2', 'ch', 'u1', 'ch', 'ang2', 'f', 'ang1', 'x', 'ing2', 'd', 'e5', 'k', 'uan1', 'd', 'u4', 'EH1', 'K', 'S', 'sp3']\n",
    "print(len(a), len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tal_frontend.frontend.ssml.xml2text import xml_reader, xml_reader_string\n",
    "from tal_frontend.frontend.ssml.xml_processor import DomXml\n",
    "\n",
    "\n",
    "text = '<speak voice_type=\"xiaosi\" rate=\"1\" pitch=\"1\" volume=\"1\" emotion=\"happy\"><break time=\"3000ms\"/><phoneme lang=\"en\" ph=\"HH AH0 L OW1/W ER1 D\">Hello word!</phoneme><break time=\"100ms\"/><phoneme lang=\"cn\" ph=\"yi4/huir2/jia1/ban1\">一会儿加班。</phoneme><break time=\"1000ms\"/>下面是latex格式的数学公式，<math interpret-as=\"latex\">\\\\triangle OCM\\cong \\\\triangle ABE</math><break time=\"1000ms\"/>下面是asciimath格式的数学公式，<math interpret-as=\"asciimath\">ax^2+bx+c=0</math>下面是mathml格式的数学公式，<math interpret-as=\"mathml\"><mi>a</mi><mrow><msup><mrow><mi>x</mi></mrow><mrow><mn>2</mn></mrow></msup></mrow><mo>+</mo><mi>b</mi><mi>x</mi><mo>+</mo><mi>c</mi><mo>=</mo><mn>0</mn></math></speak>'\n",
    "\n",
    "dom_processor = DomXml(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'好'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'好'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyphonic_chars_path = \"/mnt/cfs/NLP/hsy/audio/project/bert/g2pW/saved_models/step/v2/POLYPHONIC_CHARS_0713.txt\"\n",
    "polyphonic_chars = [line.split('\\t') for line in open(polyphonic_chars_path).read().strip().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'以'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'以':{'1':'1'}}\n",
    "list(a)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/SPEECH/hupeng/tools/env/miniconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m TAL_G2P_Triton(url)\n\u001b[1;32m      7\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m一行白鹭上青天，hello world你好z世界\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/tal_frontend/frontend/g2p_pp/g2p_client.py:275\u001b[0m, in \u001b[0;36mTAL_G2P_Triton.infer\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m    272\u001b[0m     prosodies\u001b[38;5;241m.\u001b[39mappend(rhy)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m last_lang:\n\u001b[0;32m--> 275\u001b[0m     phonemes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mword\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    276\u001b[0m     phonemes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(pho)\n\u001b[1;32m    277\u001b[0m     phonemes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m lang\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "from tal_frontend.frontend.g2p_pp.g2p_pp_client import TAL_G2P_Triton\n",
    "\n",
    "url = \"123.56.235.205:80\"\n",
    "    \n",
    "client = TAL_G2P_Triton(url)\n",
    "\n",
    "sentences = [\"一行白鹭上青天，hello world你好z世界\"]\n",
    "\n",
    "client.infer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They're boos\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = 'They\"re boos'\n",
    "\n",
    "result = re.sub(r'([a-zA-Z]+)[\"]+([a-z]+)', r\"\\1'\\2\", text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'㐬'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(13356)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('嗯')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cfs/SPEECH/hupeng/tools/env/miniconda3/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> self.bert_model_path: /mnt/cfs/NLP/hub_models/bert-base-multilingual-cased\n"
     ]
    }
   ],
   "source": [
    "from tal_frontend.frontend.g2p_pp.g2p_pp_client import TAL_G2PPP_Triton\n",
    "\n",
    "url = \"123.56.235.205:80\"\n",
    "    \n",
    "client = TAL_G2PPP_Triton(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['h', 'ui2']]\n"
     ]
    }
   ],
   "source": [
    "# sentences = ['这道题要我们解决的问题是求一个等腰三角形的顶角的度']\n",
    "sentences = [\"回\"]\n",
    "\n",
    "\n",
    "rhy_res_l, phonemes_res_l = client.infer(sentences)\n",
    "# print(rhy_res_l, phonemes_res_l)\n",
    "print(phonemes_res_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file = r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/10w_tts.json'\n",
    "with open(file, 'r', encoding='utf8') as fin:\n",
    "    fin = fin.read()\n",
    "    fin = json.loads(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = set()\n",
    "for item in fin['RECORDS']:\n",
    "    text = item['tts_output_text']\n",
    "    if text not in texts:\n",
    "        text = text.replace(\"\\n\", '')\n",
    "        texts.add(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/10w_tts_uniq.txt','w',encoding='utf8') as fo:\n",
    "    count = 1\n",
    "    for i in texts:\n",
    "        fo.write(f'{str(count).zfill(5)}\\t{i}\\n')\n",
    "        count += 1\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34593/34593 [19:06<00:00, 30.17it/s] \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from tal_frontend.tal_tts import Frontend\n",
    "ft = Frontend()\n",
    "ids, texts, nor_texts = [], [], []\n",
    "fo = open(r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/10w_tts_norm.txt', 'w', encoding='utf8')\n",
    "\n",
    "with open(r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/10w_tts_uniq.txt','r',encoding='utf8') as fin:\n",
    "    lines = fin.readlines()\n",
    "    for i in tqdm(range(len(lines))):\n",
    "        line = lines[i]\n",
    "        try:\n",
    "            key, text = line.strip().split('\\t', maxsplit=1)\n",
    "            nor_text = ft.process_text_tn(text)\n",
    "            nor_text = ' '.join([i[0] for i in nor_text])\n",
    "            fo.write(f'{key}\\t{text}\\t{nor_text}\\n')\n",
    "        except:\n",
    "            pass\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03me9326e4bb84a622e_1\t/mnt/cfs/SPEECH/data/tts/Audio_Book/part_00/seperate_data/data/book_0000/e9326e4bb84a622e.mp3\t3.4375\t15.46875\t12.03125\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      5\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/cfs/SPEECH/data/tts/Audio_Book/part_00/seperate_data/data/book_0000/e9326e4bb84a622e.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchaudio'"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "'''\n",
    "e9326e4bb84a622e_1\t/mnt/cfs/SPEECH/data/tts/Audio_Book/part_00/seperate_data/data/book_0000/e9326e4bb84a622e.mp3\t3.4375\t15.46875\t12.03125\n",
    "'''\n",
    "file = r'/mnt/cfs/SPEECH/data/tts/Audio_Book/part_00/seperate_data/data/book_0000/e9326e4bb84a622e.mp3'\n",
    "fs = 441000\n",
    "st, et = 3.4375, 15.46875\n",
    "\n",
    "audio = torchaudio.load(file, frame_offset=st*fs, num_frames=et*fs, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TAL_G2PPP_Triton.__init__() missing 8 required positional arguments: 'model_name', 'tokenizer', 'labels', 'char2phonemes', 'en_monophone', 'tonesandhi', 'zh_front', and 'en_frontend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtal_frontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfrontend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mg2p_pp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mg2p_pp_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TAL_G2PPP_Triton\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m123.56.235.205:80\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mTAL_G2PPP_Triton\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# sentences = ['这道题要我们解决的问题是求一个等腰三角形的顶角的度']\u001b[39;00m\n\u001b[1;32m      8\u001b[0m sentences \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi like eat banana, how about you?\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: TAL_G2PPP_Triton.__init__() missing 8 required positional arguments: 'model_name', 'tokenizer', 'labels', 'char2phonemes', 'en_monophone', 'tonesandhi', 'zh_front', and 'en_frontend'"
     ]
    }
   ],
   "source": [
    "from tal_frontend.frontend.g2p_pp.g2p_pp_client import TAL_G2PPP_Triton\n",
    "\n",
    "url = \"123.56.235.205:80\"\n",
    "    \n",
    "client = TAL_G2PPP_Triton(url)\n",
    "\n",
    "# sentences = ['这道题要我们解决的问题是求一个等腰三角形的顶角的度']\n",
    "sentences = [\n",
    "\"i like eat banana, how about you?\"]\n",
    "\n",
    "\n",
    "rhy_res_l, phonemes_res_l = client.infer(sentences)\n",
    "print(rhy_res_l, phonemes_res_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "刀刀见血十 d ao1 d ao1 j ian4 x ie3 sh iii2\n",
      "['x ie3']\n"
     ]
    }
   ],
   "source": [
    "from tal_frontend.frontend.g2p.zh_frontend import Frontend as zhFrontend\n",
    "import re\n",
    "\n",
    "zh_front = zhFrontend()\n",
    "words = ['刀刀见血十']\n",
    "\n",
    "for w in words:\n",
    "    ph = zh_front.get_phonemes(w)\n",
    "    print(f'{w} {ph}')\n",
    "xue = re.findall(r'x ve4|x ie3', ph)\n",
    "print(xue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x ve4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xue.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x ve4', 'x ve4', 'x ie3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tal_frontend.frontend.g2p.en_frontend import English\n",
    "en_frontend = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HH AH0 L OW1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'hello'\n",
    "en_frontend.phoneticize(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "（2,-4），\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = '（2,-4），'\n",
    "\n",
    "clean_text = re.sub(r'([\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\]\\\\\\^\\_\\`\\{\\|\\}\\~～！，。？《》/：；”“’‘【】「」！¥……（）——]{2})[\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/:;<=>\\?\\@\\[\\]\\\\\\^_`{|}~～！，。？《》/：；”“’‘【】「」！¥……（）——]+', r'\\1', text)\n",
    "\n",
    "# clean_text = re.sub(r'([\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/\\:\\;\\<\\=\\>\\?\\@\\[\\]\\\\\\^\\_\\`\\{\\|\\}\\~ ～！，。？《》/：；”“’‘【】「」！¥……（）——]){2,}', r'\\1', text)\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "fo = open(r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/3kw_query_diff.csv', 'w', encoding='utf8')\n",
    "with open(r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/3kw_query.csv', 'r', encoding='utf8') as fin:\n",
    "    for line in fin:\n",
    "        try:\n",
    "            utt, ori, tal, zijie = line.strip().split('\\t')\n",
    "            clean_zijie = zijie.lower()\n",
    "            if clean_zijie == '#n/a':\n",
    "                continue\n",
    "            clean_tal = tal.lower()\n",
    "            clean_zijie = re.findall(r'[a-z\\u4e00-\\u9fff]', clean_zijie)\n",
    "            clean_tal = re.findall(r'[a-z\\u4e00-\\u9fff]', clean_tal)\n",
    "            clean_tal = ''.join(clean_tal)\n",
    "            clean_zijie = ''.join(clean_zijie)\n",
    "            if '湿度' in clean_tal:\n",
    "                clean_tal = re.sub('百分之', '', clean_tal)\n",
    "            if clean_zijie != clean_tal and clean_zijie and clean_tal:\n",
    "                \n",
    "                tal = re.sub(r'/', '', tal)\n",
    "                zijie = re.sub(r'#\\d', '', zijie)\n",
    "                fo.write(f'{utt}\\t{ori}\\t{tal}\\t{zijie}\\n')\n",
    "        except:\n",
    "            pass\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "舞剑歌 ，唐， 李靖 ，陟崇冈兮望四围，□□闪□兮断虹飞，嗟嗟三军唱凯归。\n"
     ]
    }
   ],
   "source": [
    "from tal_frontend.frontend.normalizer.cn.cn_normalizer import cn_Normalizer as cn_Normalizer\n",
    "zh_normalizer = cn_Normalizer()\n",
    "text = '舞剑歌 ，唐， 李靖 ，陟崇冈兮望四围，□□闪□兮断虹飞，嗟嗟三军唱凯归。'\n",
    "nor_text = zh_normalizer.normalize(text)\n",
    "print(nor_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24516"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('忄')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from tal_frontend.frontend.g2p.zh_frontend import Frontend as zhFrontend\n",
    "from tal_frontend.frontend.g2p.bertg2pw.pinyin_dict import cn_monophone\n",
    "from tal_frontend.frontend.g2p.bertg2pw.tal_dict import tal_cn_dict\n",
    "\n",
    "def phoneme_convertor(phoneme):\n",
    "    if phoneme.isupper():  \n",
    "        return phoneme\n",
    "    else:\n",
    "        if phoneme == 'xer':\n",
    "            return 'er2'\n",
    "        else:\n",
    "            tone = phoneme[-1]\n",
    "            phoneme = phoneme[:-1]\n",
    "            phoneme = tal_cn_dict[phoneme] + tone\n",
    "            return phoneme\n",
    "\n",
    "zh_front = zhFrontend()\n",
    "\n",
    "\n",
    "for word, ph in cn_monophone.items():\n",
    "    try:\n",
    "        ph = phoneme_convertor(ph)\n",
    "        ph = re.sub(r'\\s', '', ph)\n",
    "    except:\n",
    "        pass\n",
    "    g2p = zh_front.get_phonemes(chr(word))\n",
    "    g2p = re.sub(r'\\s', '', g2p)\n",
    "    if g2p != ph:\n",
    "        print(chr(word), g2p, ph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "file = r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/10w_tts.json'\n",
    "with open(file, 'r') as fin:\n",
    "    fin = fin.read()\n",
    "    fin = json.loads(fin)\n",
    "\n",
    "used_id = set()\n",
    "for item in fin['RECORDS']:\n",
    "    query_trace_id = item['query_trace_id']\n",
    "    used_id.add(query_trace_id)\n",
    "file = r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/query_data_3kw.json'\n",
    "\n",
    "with open(file, 'r') as fin:\n",
    "    fin = fin.read()\n",
    "    fin = json.loads(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937419\n"
     ]
    }
   ],
   "source": [
    "res = set()\n",
    "for item in fin['RECORDS']:\n",
    "    text = item['tts_output_text']\n",
    "    if text not in res:\n",
    "        res.add(text)\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176289\n",
      "62020\n",
      "0.47854938271604935\n",
      "114269\n"
     ]
    }
   ],
   "source": [
    "text_dict = defaultdict(list)\n",
    "for item in fin['RECORDS']:\n",
    "    text = item['tts_output_text']\n",
    "    query_trace_id = item['query_trace_id']\n",
    "    if query_trace_id in used_id:\n",
    "        continue\n",
    "    if not text:\n",
    "        continue\n",
    "    text = re.sub(r'.*<.*>.*|https.*|\\n', '', text)\n",
    "    clean_text = re.sub(r'.*</.*>.*|https.*|[\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/:;<=>\\?\\@\\[\\]\\\\\\^_`{|}~\\s！，。？《》/：；”“’‘【】「」！¥……（）——\\da-zA-Z]', '', text)\n",
    "    clean_text = re.sub(r'(.*)(已为您找到|为你找到|意思是|找到多个|这样写|找到以下)(.*)',r'\\2',clean_text)\n",
    "    if not clean_text:\n",
    "        continue\n",
    "    if text_dict.get(clean_text):\n",
    "        text_dict[clean_text][1] += 1\n",
    "    else:\n",
    "        text_dict[clean_text] = [text, 1, query_trace_id]\n",
    "sorted_data = sorted(text_dict.items(), key=lambda item: item[1][1], reverse=True)\n",
    "\n",
    "num1, num2 = 0, 0\n",
    "fo1 = open(r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/uniq_3kw_data.list','w',encoding='utf8')\n",
    "fo2 = open(r'/mnt/cfs/SPEECH/hupeng/git_loc_workspace/tal_frontend_service/test_data/text/uniq_3kw_1_data.list','w',encoding='utf8')\n",
    "\n",
    "for data in sorted_data:\n",
    "    clean_text = data[0]\n",
    "    ori_text = data[1][0]\n",
    "    count = data[1][1]\n",
    "    query_trace_id = data[1][2]\n",
    "    if count > 1:\n",
    "        num1 += 1\n",
    "        fo1.write(f'{query_trace_id}\\t{clean_text}\\t{ori_text}\\t{count}\\n')\n",
    "    elif count == 1:\n",
    "        num2 +=1 \n",
    "        fo2.write(f'{query_trace_id}\\t{clean_text}\\t{ori_text}\\t{count}\\n')\n",
    "            \n",
    "fo1.close()\n",
    "fo2.close()\n",
    "print(len(sorted_data))\n",
    "print(num1)\n",
    "print(num1 / 1.5 / 3600 / 24)\n",
    "print(num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "的意思是：决定；决心；决议；结论；裁决；判定.\n",
      "意思是\n"
     ]
    }
   ],
   "source": [
    "text = '的意思是：决定；决心；决议；结论；裁决；判定.'\n",
    "text = re.sub(r'.*</.*>.*|https.*|\\n', '', text)\n",
    "print(text)\n",
    "clean_text = re.sub(r'.*</.*>.*|https.*|[\\!\\\"\\#\\$\\%\\&\\'\\(\\)\\*\\+\\,\\-\\.\\/:;<=>\\?\\@\\[\\]\\\\\\^_`{|}~\\s！，。？《》/：；”“’‘【】「」！¥……（）——\\da-zA-Z]', '', text)\n",
    "\n",
    "clean_text = re.sub(r'(.*)(已为您找到|为你找到|意思是|找到多个|这样写|找到以下)(.*)',r'\\2',clean_text)\n",
    "\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "竖心旁和心理活动或心情有关。【忄】作为部首叫：竖心旁【忄】读音： 西因心 ，意思是：同“心”，用作偏旁。俗称“竖心旁”，简称“竖心”。【忄】的笔顺：点、点、竖含有【忄】的字：怡、惨、憾、忧、悦\n",
      "NWC\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tal_frontend.utils.special_words import special_words\n",
    "text = '竖心旁和心理活动或心情有关。【忄】作为部首叫：竖心旁【忄】读音： xīn ，意思是：同“心”，用作偏旁。俗称“竖心旁”，简称“竖心”。【忄】的笔顺：点、点、竖含有【忄】的字：怡、惨、憾、忧、悦'\n",
    "for key, value in special_words.items():\n",
    "    text = re.sub(key, value, text)\n",
    "print(text)\n",
    "\n",
    "word = 'NWC'\n",
    "if re.match(r'[a-zA-Z]', word):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IH1 G AH0 L'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tal_frontend.frontend.g2p.en_frontend import English\n",
    "\n",
    "en = English()\n",
    "en.phoneticize('igl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全文是这样的： 你好` 这首诗\n",
      "1\n",
      "youre\n",
      "girl.mrDr\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "nor_text = '全文是这样的：,```你好```这首诗'\n",
    "nor_text = re.sub(r'([：,`])[,`]+', r'\\1 ', nor_text)\n",
    "print(nor_text)\n",
    "\n",
    "word = \"you're\"\n",
    "if re.match(r'[a-zA-Z]', word):\n",
    "    print(1)\n",
    "    \n",
    "text = \"you----re\"\n",
    "text = re.sub(r'([a-zA-Z]+)[\\'\\-]+([a-zA-Z]+)',r'\\1\\2',text)\n",
    "print(text)\n",
    "\n",
    "text = \"girl.mr.Dr\"\n",
    "sentence = re.sub(r'(mr|Mr|Ms|ms|dr|Dr)\\.', r'\\1', text)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you',\n",
       " \"'\",\n",
       " 're',\n",
       " ' ',\n",
       " 'beatiful',\n",
       " ',',\n",
       " ' ',\n",
       " 'a',\n",
       " ' ',\n",
       " 'good',\n",
       " '-',\n",
       " 'looking',\n",
       " ' ',\n",
       " 'girl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "text = \"you're beatiful, a good-looking girl\"\n",
    "\n",
    "jieba.lcut(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"you're beatiful, a good-looking girl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youre\n",
      "beatiful\n",
      "a\n",
      "good\n",
      "looking\n",
      "girl\n"
     ]
    }
   ],
   "source": [
    "a =  ['youre', ' ', 'beatiful', ',', 'a', ' ', 'good', ' ', 'looking', ' ', 'girl']\n",
    "for i in a:\n",
    "    if re.search(r'[a-z]+', i):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tal_frontend.frontend.ssml.xml2text import xml_reader, xml_reader_string\n",
    "\n",
    "ssml = '<speak voice_type=\\\"\\\" rate=\\\"1.1\\\" pitch=\\\"1.0\\\" volume=\\\"90\\\" emotion=\\\"cheerful\\\">整顿衣<phoneme lang=\\\"cn\\\" ph=\\\"shang5\\\">裳</phoneme>起敛容。</speak>'\n",
    "\n",
    "contents, speak_info = xml_reader_string(ssml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['text', '', '整顿衣'], ['pinyin', 'sh ang5/', '裳'], ['text', '', '起敛容。']]\n"
     ]
    }
   ],
   "source": [
    "print(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import json\n",
    "\n",
    "\n",
    "# prod\n",
    "redis_client = redis.Redis(host=\"r-2ze7sx5pe00o4w0mer.redis.rds.aliyuncs.com\",\n",
    "                           port=6379,\n",
    "                           password=\"DySfiNWD9Ilwa91_\",\n",
    "                           db=8)\n",
    "\n",
    "# ['整 顿 衣 裳 起 敛 容 ', ['zh eng3', 'd uen4', 'i1', 'sh ang5', 'q i3', 'l ian3', 'r ong2'], 'cn']\n",
    "\n",
    "# write_key = \"整顿衣裳起敛容\"\n",
    "# write_value = json.dumps([\"zheng3 duen4 i1 shang5 qi3 lian3 rong2\",\"整顿衣裳起敛容#4\"],ensure_ascii=False)\n",
    "# redis_client.set(write_key,write_value)\n",
    "\n",
    "# res = redis_client.get(write_key)\n",
    "# print(json.loads(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b ei3', 'j ing1', ' sp3', ' iou2', 'h en3', 'd uo1', ' iou3', 'q v5', 'd e5', 'd i5', 'f ang5']\n",
      "['b ei3', 'j ing1', ' iou3', 'h en3', 'd uo1', ' iou3', 'q v4', 'd e5', 'd i4', 'f ang5', ' o5']\n"
     ]
    }
   ],
   "source": [
    "from tal_frontend.frontend.g2p.tone_sandhi import ToneSandhi\n",
    "\n",
    "ts = ToneSandhi()\n",
    "\n",
    "text = '北 京 有 很 多 有 趣 的 地 方 哦 '\n",
    "\n",
    "phs = ['b ei3', 'j ing1', 'sp3', 'iou3', 'h en3', 'd uo1', 'iou3', 'q v4', 'd e5', 'd i4', 'f ang1', 'o5']\n",
    "\n",
    "res = ts.modified_tone(text, phs)\n",
    "print(res)\n",
    "\n",
    "text = '北 京 有 很 多 有 趣 的 地 方 哦 '\n",
    "\n",
    "phs = ['b ei3', 'j ing1',  'iou3', 'h en3', 'd uo1', 'iou3', 'q v4', 'd e5', 'd i4', 'f ang1', 'o5']\n",
    "\n",
    "res = ts.modified_tone(text, phs)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "氢-\t氢\n",
      "氦-\t氦\n",
      "锂-\t锂\n",
      "铍-\t铍\n",
      "硼-\t硼\n",
      "碳-\t碳\n",
      "氮-\t氮\n",
      "氧-\t氧\n",
      "氟-\t氟\n",
      "氖-\t氖\n",
      "钠-\t钠\n",
      "镁-\t镁\n",
      "铝-\t铝\n",
      "硅-\t硅\n",
      "磷-\t磷\n",
      "硫-\t硫\n",
      "氯-\t氯\n",
      "氩-\t氩\n",
      "钾-\t钾\n",
      "钙-\t钙\n",
      "钪-\t钪\n",
      "钛-\t钛\n",
      "钒-\t钒\n",
      "铬-\t铬\n",
      "锰-\t锰\n",
      "铁-\t铁\n",
      "钴-\t钴\n",
      "镍-\t镍\n",
      "铜-\t铜\n",
      "锌-\t锌\n",
      "镓-\t镓\n",
      "锗-\t锗\n",
      "砷-\t砷\n",
      "硒-\t硒\n",
      "溴-\t溴\n",
      "氪-\t氪\n",
      "铷-\t铷\n",
      "锶-\t锶\n",
      "钇-\t钇\n",
      "锆-\t锆\n",
      "铌-\t铌\n",
      "钼-\t钼\n",
      "锝-\t锝\n",
      "钌-\t钌\n",
      "铑-\t铑\n",
      "钯-\t钯\n",
      "银-\t银\n",
      "镉-\t镉\n",
      "铟-\t铟\n",
      "锡-\t锡\n",
      "锑-\t锑\n",
      "碲-\t碲\n",
      "碘-\t碘\n",
      "氙-\t氙\n",
      "铯-\t铯\n",
      "钡-\t钡\n",
      "镧-\t镧\n",
      "铈-\t铈\n",
      "镨-\t镨\n",
      "钕-\t钕\n",
      "钷-\t钷\n",
      "钐-\t钐\n",
      "铕-\t铕\n",
      "钆-\t钆\n",
      "铽-\t铽\n",
      "镝-\t镝\n",
      "钬-\t钬\n",
      "铒-\t铒\n",
      "铥-\t铥\n",
      "镱-\t镱\n",
      "镥-\t镥\n",
      "铪-\t铪\n",
      "钽-\t钽\n",
      "钨-\t钨\n",
      "铼-\t铼\n",
      "锇-\t锇\n",
      "铱-\t铱\n",
      "铂-\t铂\n",
      "金-\t金\n",
      "汞-\t汞\n",
      "铊-\t铊\n",
      "铅-\t铅\n",
      "铋-\t铋\n",
      "钋-\t钋\n",
      "砹-\t砹\n",
      "氡-\t氡\n",
      "钫-\t钫\n",
      "镭-\t镭\n",
      "锕-\t锕\n",
      "钍-\t钍\n",
      "镤-\t镤\n",
      "铀-\t铀\n",
      "镎-\t镎\n",
      "钚-\t钚\n",
      "镅-\t镅\n",
      "锔-\t锔\n",
      "锫-\t锫\n",
      "锎-\t锎\n",
      "锿-\t锿\n",
      "镄-\t镄\n",
      "钔-\t钔\n",
      "锘-\t锘\n",
      "铹-\t铹\n",
      "镆-\t镆\n"
     ]
    }
   ],
   "source": [
    "elements = {\n",
    "    \"H\": {\"中文名\": \"氢\", \"拼音\": \"qīng\"},\n",
    "    \"He\": {\"中文名\": \"氦\", \"拼音\": \"hài\"},\n",
    "    \"Li\": {\"中文名\": \"锂\", \"拼音\": \"lǐ\"},\n",
    "    \"Be\": {\"中文名\": \"铍\", \"拼音\": \"pí\"},\n",
    "    \"B\": {\"中文名\": \"硼\", \"拼音\": \"péng\"},\n",
    "    \"C\": {\"中文名\": \"碳\", \"拼音\": \"tàn\"},\n",
    "    \"N\": {\"中文名\": \"氮\", \"拼音\": \"dàn\"},\n",
    "    \"O\": {\"中文名\": \"氧\", \"拼音\": \"yǎng\"},\n",
    "    \"F\": {\"中文名\": \"氟\", \"拼音\": \"fú\"},\n",
    "    \"Ne\": {\"中文名\": \"氖\", \"拼音\": \"nǎi\"},\n",
    "    \"Na\": {\"中文名\": \"钠\", \"拼音\": \"nà\"},\n",
    "    \"Mg\": {\"中文名\": \"镁\", \"拼音\": \"měi\"},\n",
    "    \"Al\": {\"中文名\": \"铝\", \"拼音\": \"lǚ\"},\n",
    "    \"Si\": {\"中文名\": \"硅\", \"拼音\": \"guī\"},\n",
    "    \"P\": {\"中文名\": \"磷\", \"拼音\": \"lín\"},\n",
    "    \"S\": {\"中文名\": \"硫\", \"拼音\": \"liú\"},\n",
    "    \"Cl\": {\"中文名\": \"氯\", \"拼音\": \"lǜ\"},\n",
    "    \"Ar\": {\"中文名\": \"氩\", \"拼音\": \"yà\"},\n",
    "    \"K\": {\"中文名\": \"钾\", \"拼音\": \"jiǎ\"},\n",
    "    \"Ca\": {\"中文名\": \"钙\", \"拼音\": \"gài\"},\n",
    "    \"Sc\": {\"中文名\": \"钪\", \"拼音\": \"kàng\"},\n",
    "    \"Ti\": {\"中文名\": \"钛\", \"拼音\": \"tài\"},\n",
    "    \"V\": {\"中文名\": \"钒\", \"拼音\": \"fán\"},\n",
    "    \"Cr\": {\"中文名\": \"铬\", \"拼音\": \"gè\"},\n",
    "    \"Mn\": {\"中文名\": \"锰\", \"拼音\": \"měng\"},\n",
    "    \"Fe\": {\"中文名\": \"铁\", \"拼音\": \"tiě\"},\n",
    "    \"Co\": {\"中文名\": \"钴\", \"拼音\": \"gǔ\"},\n",
    "    \"Ni\": {\"中文名\": \"镍\", \"拼音\": \"niè\"},\n",
    "    \"Cu\": {\"中文名\": \"铜\", \"拼音\": \"tóng\"},\n",
    "    \"Zn\": {\"中文名\": \"锌\", \"拼音\": \"xīn\"},\n",
    "    \"Ga\": {\"中文名\": \"镓\", \"拼音\": \"jiā\"},\n",
    "    \"Ge\": {\"中文名\": \"锗\", \"拼音\": \"zhě\"},\n",
    "    \"As\": {\"中文名\": \"砷\", \"拼音\": \"shēn\"},\n",
    "    \"Se\": {\"中文名\": \"硒\", \"拼音\": \"xī\"},\n",
    "    \"Br\": {\"中文名\": \"溴\", \"拼音\": \"xiù\"},\n",
    "    \"Kr\": {\"中文名\": \"氪\", \"拼音\": \"kè\"},\n",
    "    \"Rb\": {\"中文名\": \"铷\", \"拼音\": \"rú\"},\n",
    "    \"Sr\": {\"中文名\": \"锶\", \"拼音\": \"sī\"},\n",
    "    \"Y\": {\"中文名\": \"钇\", \"拼音\": \"yǐ\"},\n",
    "    \"Zr\": {\"中文名\": \"锆\", \"拼音\": \"gào\"},\n",
    "    \"Nb\": {\"中文名\": \"铌\", \"拼音\": \"ní\"},\n",
    "    \"Mo\": {\"中文名\": \"钼\", \"拼音\": \"mù\"},\n",
    "    \"Tc\": {\"中文名\": \"锝\", \"拼音\": \"dé\"},\n",
    "    \"Ru\": {\"中文名\": \"钌\", \"拼音\": \"liǎo\"},\n",
    "    \"Rh\": {\"中文名\": \"铑\", \"拼音\": \"lǎo\"},\n",
    "    \"Pd\": {\"中文名\": \"钯\", \"拼音\": \"bǎ\"},\n",
    "    \"Ag\": {\"中文名\": \"银\", \"拼音\": \"yín\"},\n",
    "    \"Cd\": {\"中文名\": \"镉\", \"拼音\": \"gé\"},\n",
    "    \"In\": {\"中文名\": \"铟\", \"拼音\": \"yīn\"},\n",
    "    \"Sn\": {\"中文名\": \"锡\", \"拼音\": \"xī\"},\n",
    "    \"Sb\": {\"中文名\": \"锑\", \"拼音\": \"tī\"},\n",
    "    \"Te\": {\"中文名\": \"碲\", \"拼音\": \"dì\"},\n",
    "    \"I\": {\"中文名\": \"碘\", \"拼音\": \"diǎn\"},\n",
    "    \"Xe\": {\"中文名\": \"氙\", \"拼音\": \"xiān\"},\n",
    "    \"Cs\": {\"中文名\": \"铯\", \"拼音\": \"sè\"},\n",
    "    \"Ba\": {\"中文名\": \"钡\", \"拼音\": \"bèi\"},\n",
    "    \"La\": {\"中文名\": \"镧\", \"拼音\": \"lán\"},\n",
    "    \"Ce\": {\"中文名\": \"铈\", \"拼音\": \"shì\"},\n",
    "    \"Pr\": {\"中文名\": \"镨\", \"拼音\": \"pǔ\"},\n",
    "    \"Nd\": {\"中文名\": \"钕\", \"拼音\": \"nǚ\"},\n",
    "    \"Pm\": {\"中文名\": \"钷\", \"拼音\": \"pǒ\"},\n",
    "    \"Sm\": {\"中文名\": \"钐\", \"拼音\": \"shān\"},\n",
    "    \"Eu\": {\"中文名\": \"铕\", \"拼音\": \"yǒu\"},\n",
    "    \"Gd\": {\"中文名\": \"钆\", \"拼音\": \"gá\"},\n",
    "    \"Tb\": {\"中文名\": \"铽\", \"拼音\": \"tè\"},\n",
    "    \"Dy\": {\"中文名\": \"镝\", \"拼音\": \"dī\"},\n",
    "    \"Ho\": {\"中文名\": \"钬\", \"拼音\": \"huǒ\"},\n",
    "    \"Er\": {\"中文名\": \"铒\", \"拼音\": \"ěr\"},\n",
    "    \"Tm\": {\"中文名\": \"铥\", \"拼音\": \"diū\"},\n",
    "    \"Yb\": {\"中文名\": \"镱\", \"拼音\": \"yì\"},\n",
    "    \"Lu\": {\"中文名\": \"镥\", \"拼音\": \"lǔ\"},\n",
    "    \"Hf\": {\"中文名\": \"铪\", \"拼音\": \"hā\"},\n",
    "    \"Ta\": {\"中文名\": \"钽\", \"拼音\": \"tǎn\"},\n",
    "    \"W\": {\"中文名\": \"钨\", \"拼音\": \"wū\"},\n",
    "    \"Re\": {\"中文名\": \"铼\", \"拼音\": \"lái\"},\n",
    "    \"Os\": {\"中文名\": \"锇\", \"拼音\": \"é\"},\n",
    "    \"Ir\": {\"中文名\": \"铱\", \"拼音\": \"yī\"},\n",
    "    \"Pt\": {\"中文名\": \"铂\", \"拼音\": \"bó\"},\n",
    "    \"Au\": {\"中文名\": \"金\", \"拼音\": \"jīn\"},\n",
    "    \"Hg\": {\"中文名\": \"汞\", \"拼音\": \"gǒng\"},\n",
    "    \"Tl\": {\"中文名\": \"铊\", \"拼音\": \"tā\"},\n",
    "    \"Pb\": {\"中文名\": \"铅\", \"拼音\": \"qiān\"},\n",
    "    \"Bi\": {\"中文名\": \"铋\", \"拼音\": \"bì\"},\n",
    "    \"Po\": {\"中文名\": \"钋\", \"拼音\": \"pō\"},\n",
    "    \"At\": {\"中文名\": \"砹\", \"拼音\": \"ài\"},\n",
    "    \"Rn\": {\"中文名\": \"氡\", \"拼音\": \"dōng\"},\n",
    "    \"Fr\": {\"中文名\": \"钫\", \"拼音\": \"fāng\"},\n",
    "    \"Ra\": {\"中文名\": \"镭\", \"拼音\": \"léi\"},\n",
    "    \"Ac\": {\"中文名\": \"锕\", \"拼音\": \"ā\"},\n",
    "    \"Th\": {\"中文名\": \"钍\", \"拼音\": \"tǔ\"},\n",
    "    \"Pa\": {\"中文名\": \"镤\", \"拼音\": \"pú\"},\n",
    "    \"U\": {\"中文名\": \"铀\", \"拼音\": \"yóu\"},\n",
    "    \"Np\": {\"中文名\": \"镎\", \"拼音\": \"ná\"},\n",
    "    \"Pu\": {\"中文名\": \"钚\", \"拼音\": \"bù\"},\n",
    "    \"Am\": {\"中文名\": \"镅\", \"拼音\": \"méi\"},\n",
    "    \"Cm\": {\"中文名\": \"锔\", \"拼音\": \"jú\"},\n",
    "    \"Bk\": {\"中文名\": \"锫\", \"拼音\": \"péi\"},\n",
    "    \"Cf\": {\"中文名\": \"锎\", \"拼音\": \"kāi\"},\n",
    "    \"Es\": {\"中文名\": \"锿\", \"拼音\": \"āi\"},\n",
    "    \"Fm\": {\"中文名\": \"镄\", \"拼音\": \"fèi\"},\n",
    "    \"Md\": {\"中文名\": \"钔\", \"拼音\": \"mén\"},\n",
    "    \"No\": {\"中文名\": \"锘\", \"拼音\": \"nuò\"},\n",
    "    \"Lr\": {\"中文名\": \"铹\", \"拼音\": \"láo\"},\n",
    "    \"Mc\": {\"中文名\": \"镆\", \"拼音\": \"mò\"},\n",
    "}\n",
    "\n",
    "for key, value in elements.items():\n",
    "    name = value['中文名']\n",
    "    a = f'{name}-\\t{name}'\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
